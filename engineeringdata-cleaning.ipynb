{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import chardet\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados Combustivel Automotivo - CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.read_csv(\"dataset/datasetCA-2014-2024/ca-2024-02.csv\", engine=\"python\", encoding=\"latin1\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 421382 entries, 0 to 421381\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   ï»¿Regiao - Sigla  421382 non-null  object \n",
      " 1   Estado - Sigla     421382 non-null  object \n",
      " 2   Municipio          421382 non-null  object \n",
      " 3   Revenda            421382 non-null  object \n",
      " 4   CNPJ da Revenda    421382 non-null  object \n",
      " 5   Nome da Rua        421382 non-null  object \n",
      " 6   Numero Rua         421282 non-null  object \n",
      " 7   Complemento        94698 non-null   object \n",
      " 8   Bairro             420809 non-null  object \n",
      " 9   Cep                421382 non-null  object \n",
      " 10  Produto            421382 non-null  object \n",
      " 11  Data da Coleta     421382 non-null  object \n",
      " 12  Valor de Venda     421382 non-null  object \n",
      " 13  Valor de Compra    0 non-null       float64\n",
      " 14  Unidade de Medida  421382 non-null  object \n",
      " 15  Bandeira           421382 non-null  object \n",
      "dtypes: float64(1), object(15)\n",
      "memory usage: 51.4+ MB\n"
     ]
    }
   ],
   "source": [
    "dff.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.to_csv('ca-2024-02-utf8.csv', index=False, encoding='utf-8-sig', sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo processado e salvo em: dataset\\datasetCA-renomeado-convertido\\ca-2014-01.csv\n",
      "Arquivo processado e salvo em: dataset\\datasetCA-renomeado-convertido\\ca-2014-02.csv\n",
      "Arquivo processado e salvo em: dataset\\datasetCA-renomeado-convertido\\ca-2015-01.csv\n",
      "Arquivo processado e salvo em: dataset\\datasetCA-renomeado-convertido\\ca-2015-02.csv\n",
      "Arquivo processado e salvo em: dataset\\datasetCA-renomeado-convertido\\ca-2016-01.csv\n",
      "Arquivo processado e salvo em: dataset\\datasetCA-renomeado-convertido\\ca-2016-02.csv\n",
      "Arquivo processado e salvo em: dataset\\datasetCA-renomeado-convertido\\ca-2017-01.csv\n",
      "Arquivo processado e salvo em: dataset\\datasetCA-renomeado-convertido\\ca-2017-02.csv\n",
      "Arquivo processado e salvo em: dataset\\datasetCA-renomeado-convertido\\ca-2018-01.csv\n",
      "Arquivo processado e salvo em: dataset\\datasetCA-renomeado-convertido\\ca-2018-02.csv\n",
      "Arquivo processado e salvo em: dataset\\datasetCA-renomeado-convertido\\ca-2019-01.csv\n",
      "Arquivo processado e salvo em: dataset\\datasetCA-renomeado-convertido\\ca-2019-02.csv\n",
      "Arquivo processado e salvo em: dataset\\datasetCA-renomeado-convertido\\ca-2020-01.csv\n",
      "Arquivo processado e salvo em: dataset\\datasetCA-renomeado-convertido\\ca-2020-02.csv\n",
      "Arquivo processado e salvo em: dataset\\datasetCA-renomeado-convertido\\ca-2021-01.csv\n",
      "Arquivo processado e salvo em: dataset\\datasetCA-renomeado-convertido\\ca-2021-02.csv\n",
      "Arquivo processado e salvo em: dataset\\datasetCA-renomeado-convertido\\ca-2022-01.csv\n",
      "Arquivo processado e salvo em: dataset\\datasetCA-renomeado-convertido\\ca-2022-02.csv\n",
      "Arquivo processado e salvo em: dataset\\datasetCA-renomeado-convertido\\ca-2023-01.csv\n",
      "Arquivo processado e salvo em: dataset\\datasetCA-renomeado-convertido\\ca-2023-02.csv\n",
      "Arquivo processado e salvo em: dataset\\datasetCA-renomeado-convertido\\ca-2024-01.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def renomear_colunas(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Se a coluna vier com BOM (ï»¿Regiao - Sigla)\n",
    "    if 'ï»¿Regiao - Sigla' in df.columns:\n",
    "        df.rename(columns={'ï»¿Regiao - Sigla': 'Regiao - Sigla'}, inplace=True)\n",
    "    \n",
    "    # Renomeia todas as colunas, removendo espaços, hífens, etc.\n",
    "    df.columns = (\n",
    "        df.columns\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(' ', '_') \n",
    "        .str.replace('-', '_')\n",
    "        .str.replace('[()]', '', regex=True)\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def processar_arquivos_csv(input_pattern: str, output_folder: str):\n",
    "    # Lista todos os arquivos que batem com o padrão\n",
    "    csv_files = glob.glob(input_pattern)\n",
    "    \n",
    "    # Garante que a pasta de saída existe\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    for file_path in csv_files:\n",
    "        # Lê o CSV; ajuste sep e encoding conforme seus dados\n",
    "        df = pd.read_csv(file_path, sep=';', encoding='utf-8-sig', low_memory=False)\n",
    "        \n",
    "        # Renomeia as colunas\n",
    "        df = renomear_colunas(df)\n",
    "        \n",
    "        # Gera nome do arquivo de saída (mesmo nome, mas em outra pasta)\n",
    "        base_name = os.path.basename(file_path)  # ex: 'arquivo.csv'\n",
    "        output_path = os.path.join(output_folder, base_name)\n",
    "    \n",
    "        df.to_csv(output_path, index=False, sep=';', encoding='utf-8-sig')\n",
    "        \n",
    "        print(f\"Arquivo processado e salvo em: {output_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pasta_entrada = r'dataset\\datasetCA-2014-2024\\**.csv'\n",
    "    pasta_saida = r'dataset\\datasetCA-renomeado-convertido'\n",
    "    \n",
    "    processar_arquivos_csv(pasta_entrada, pasta_saida)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 473636 entries, 0 to 473635\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   regiao___sigla     473636 non-null  object \n",
      " 1   estado___sigla     473636 non-null  object \n",
      " 2   municipio          473636 non-null  object \n",
      " 3   revenda            473636 non-null  object \n",
      " 4   cnpj_da_revenda    473636 non-null  object \n",
      " 5   nome_da_rua        473636 non-null  object \n",
      " 6   numero_rua         473412 non-null  object \n",
      " 7   complemento        125453 non-null  object \n",
      " 8   bairro             471933 non-null  object \n",
      " 9   cep                473636 non-null  object \n",
      " 10  produto            473636 non-null  object \n",
      " 11  data_da_coleta     473635 non-null  object \n",
      " 12  valor_de_venda     473635 non-null  float64\n",
      " 13  valor_de_compra    197685 non-null  float64\n",
      " 14  unidade_de_medida  473635 non-null  object \n",
      " 15  bandeira           473635 non-null  object \n",
      "dtypes: float64(2), object(14)\n",
      "memory usage: 57.8+ MB\n"
     ]
    }
   ],
   "source": [
    "dfca = pd.read_csv('dataset/datasetCA-renomeado-convertido/ca-2014-01.csv',  engine=\"python\", sep=\";\")\n",
    "dfca.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def juntar_arquivos_csv(input_pattern: str, output_csv: str):\n",
    "    # Lista todos os arquivos CSV do padrão\n",
    "    csv_files = glob.glob(input_pattern)\n",
    "    \n",
    "    df_list = []\n",
    "    for file_path in csv_files:\n",
    "        print(f\"Lendo arquivo: {file_path}\")\n",
    "        df_temp = pd.read_csv(file_path, sep=';', encoding='utf-8-sig', low_memory=False)\n",
    "        \n",
    "        df_list.append(df_temp)\n",
    "    \n",
    "    # Concatena todos os DataFrames em um só\n",
    "    df_final = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    # Salva em um único CSV\n",
    "    df_final.to_csv(output_csv, index=False, sep=';', encoding='utf-8-sig')\n",
    "    print(f\"\\nArquivo final unificado salvo em: {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo arquivo: dataset\\datasetCA-renomeado-convertido\\ca-2014-01.csv\n",
      "Lendo arquivo: dataset\\datasetCA-renomeado-convertido\\ca-2014-02.csv\n",
      "Lendo arquivo: dataset\\datasetCA-renomeado-convertido\\ca-2015-01.csv\n",
      "Lendo arquivo: dataset\\datasetCA-renomeado-convertido\\ca-2015-02.csv\n",
      "Lendo arquivo: dataset\\datasetCA-renomeado-convertido\\ca-2016-01.csv\n",
      "Lendo arquivo: dataset\\datasetCA-renomeado-convertido\\ca-2016-02.csv\n",
      "Lendo arquivo: dataset\\datasetCA-renomeado-convertido\\ca-2017-01.csv\n",
      "Lendo arquivo: dataset\\datasetCA-renomeado-convertido\\ca-2017-02.csv\n",
      "Lendo arquivo: dataset\\datasetCA-renomeado-convertido\\ca-2018-01.csv\n",
      "Lendo arquivo: dataset\\datasetCA-renomeado-convertido\\ca-2018-02.csv\n",
      "Lendo arquivo: dataset\\datasetCA-renomeado-convertido\\ca-2019-01.csv\n",
      "Lendo arquivo: dataset\\datasetCA-renomeado-convertido\\ca-2019-02.csv\n",
      "Lendo arquivo: dataset\\datasetCA-renomeado-convertido\\ca-2020-01.csv\n",
      "Lendo arquivo: dataset\\datasetCA-renomeado-convertido\\ca-2020-02.csv\n",
      "Lendo arquivo: dataset\\datasetCA-renomeado-convertido\\ca-2021-01.csv\n",
      "Lendo arquivo: dataset\\datasetCA-renomeado-convertido\\ca-2021-02.csv\n",
      "Lendo arquivo: dataset\\datasetCA-renomeado-convertido\\ca-2022-01.csv\n",
      "Lendo arquivo: dataset\\datasetCA-renomeado-convertido\\ca-2022-02.csv\n",
      "Lendo arquivo: dataset\\datasetCA-renomeado-convertido\\ca-2023-01.csv\n",
      "Lendo arquivo: dataset\\datasetCA-renomeado-convertido\\ca-2023-02.csv\n",
      "Lendo arquivo: dataset\\datasetCA-renomeado-convertido\\ca-2024-01.csv\n",
      "\n",
      "Arquivo final unificado salvo em: data_unificados.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    caminho_entrada = r'dataset\\datasetCA-renomeado-convertido\\*.csv'\n",
    "    caminho_saida = r'data_unificados.csv'\n",
    "    \n",
    "    juntar_arquivos_csv(caminho_entrada, caminho_saida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfteste  = pd.read_csv('data_unificados.csv', sep=';', encoding='utf-8-sig', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9799985 entries, 0 to 9799984\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   regiao___sigla     object \n",
      " 1   estado___sigla     object \n",
      " 2   municipio          object \n",
      " 3   revenda            object \n",
      " 4   cnpj_da_revenda    object \n",
      " 5   nome_da_rua        object \n",
      " 6   numero_rua         object \n",
      " 7   complemento        object \n",
      " 8   bairro             object \n",
      " 9   cep                object \n",
      " 10  produto            object \n",
      " 11  data_da_coleta     object \n",
      " 12  valor_de_venda     float64\n",
      " 13  valor_de_compra    float64\n",
      " 14  unidade_de_medida  object \n",
      " 15  bandeira           object \n",
      "dtypes: float64(2), object(14)\n",
      "memory usage: 1.2+ GB\n"
     ]
    }
   ],
   "source": [
    "dfteste.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfuni = pd.read_csv('data_unificados.csv', sep=';', low_memory=False)\n",
    "\n",
    "# 2) Criar a nova coluna de data, fazendo a conversão\n",
    "dfuni['data_da_coleta_nova'] = pd.to_datetime(\n",
    "    dfuni['data_da_coleta'].astype(str).str.strip(),\n",
    "    format='%Y-%m-%d',\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# 3) Remove a coluna original\n",
    "dfuni.drop(columns=['data_da_coleta'], inplace=True)\n",
    "\n",
    "# 4) Renomear a nova coluna para o nome original\n",
    "dfuni.rename(columns={'data_da_coleta_nova': 'data_da_coleta'}, inplace=True)\n",
    "\n",
    "dfuni.to_csv('data_unificados.csv', sep=';', encoding='utf-8-sig', index=False)\n",
    "\n",
    "print(\"Coluna de data convertida e salva no arquivo:\", 'data_unificados.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversão finalizada e arquivo sobrescrito.\n"
     ]
    }
   ],
   "source": [
    "# Define as colunas que NÃO devem virar string\n",
    "cols_excecao = ['valor_de_venda', 'valor_de_compra', 'data_da_coleta']\n",
    "\n",
    "for col in dfuni.columns:\n",
    "    # Pule se estiver na exceção\n",
    "    if col in cols_excecao:\n",
    "        continue\n",
    "    \n",
    "    # Cria o nome da nova coluna\n",
    "    col_nova = col + '_novo'\n",
    "    \n",
    "    # Converte para string\n",
    "    dfuni[col_nova] = dfuni[col].astype('string')\n",
    "    \n",
    "    # Remove a coluna original\n",
    "    dfuni.drop(columns=[col], inplace=True)\n",
    "    \n",
    "    # Renomeia a nova coluna para o nome antigo\n",
    "    dfuni.rename(columns={col_nova: col}, inplace=True)\n",
    "\n",
    "# Pronto: agora todas as colunas (exceto as 3 na lista de exceção)\n",
    "# estão em formato string, mas mantêm o mesmo nome final.\n",
    "\n",
    "# Salva no mesmo arquivo (sobrescrevendo) ou escolha outro nome\n",
    "dfuni.to_csv(r'data_unificados.csv', sep=';', index=False)\n",
    "print(\"Conversão finalizada e arquivo sobrescrito.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9799985 entries, 0 to 9799984\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Dtype         \n",
      "---  ------             -----         \n",
      " 0   valor_de_venda     float64       \n",
      " 1   valor_de_compra    float64       \n",
      " 2   data_da_coleta     datetime64[ns]\n",
      " 3   regiao___sigla     string        \n",
      " 4   estado___sigla     string        \n",
      " 5   municipio          string        \n",
      " 6   revenda            string        \n",
      " 7   cnpj_da_revenda    string        \n",
      " 8   nome_da_rua        string        \n",
      " 9   numero_rua         string        \n",
      " 10  complemento        string        \n",
      " 11  bairro             string        \n",
      " 12  cep                string        \n",
      " 13  produto            string        \n",
      " 14  unidade_de_medida  string        \n",
      " 15  bandeira           string        \n",
      "dtypes: datetime64[ns](1), float64(2), string(13)\n",
      "memory usage: 1.2 GB\n"
     ]
    }
   ],
   "source": [
    "data_unificados = pd.read_pickle('data_unificados.pkl')\n",
    "data_unificados.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados Extas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfga = pd.read_csv(\"dataset/precos-gasolina-etanol-01.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Regiao - Sigla</th>\n",
       "      <th>Estado - Sigla</th>\n",
       "      <th>Municipio</th>\n",
       "      <th>Revenda</th>\n",
       "      <th>CNPJ da Revenda</th>\n",
       "      <th>Nome da Rua</th>\n",
       "      <th>Numero Rua</th>\n",
       "      <th>Complemento</th>\n",
       "      <th>Bairro</th>\n",
       "      <th>Cep</th>\n",
       "      <th>Produto</th>\n",
       "      <th>Data da Coleta</th>\n",
       "      <th>Valor de Venda</th>\n",
       "      <th>Valor de Compra</th>\n",
       "      <th>Unidade de Medida</th>\n",
       "      <th>Bandeira</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N</td>\n",
       "      <td>AC</td>\n",
       "      <td>RIO BRANCO</td>\n",
       "      <td>AUTO POSTO AMAPA - EIRELI</td>\n",
       "      <td>00.529.581/0001-53</td>\n",
       "      <td>VIA CHICO MENDES</td>\n",
       "      <td>3570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AREAL</td>\n",
       "      <td>69906-119</td>\n",
       "      <td>GASOLINA</td>\n",
       "      <td>03/01/2022</td>\n",
       "      <td>6,99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R$ / litro</td>\n",
       "      <td>VIBRA ENERGIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "      <td>AC</td>\n",
       "      <td>RIO BRANCO</td>\n",
       "      <td>AUTO POSTO AMAPA - EIRELI</td>\n",
       "      <td>00.529.581/0001-53</td>\n",
       "      <td>VIA CHICO MENDES</td>\n",
       "      <td>3570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AREAL</td>\n",
       "      <td>69906-119</td>\n",
       "      <td>ETANOL</td>\n",
       "      <td>03/01/2022</td>\n",
       "      <td>5,99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R$ / litro</td>\n",
       "      <td>VIBRA ENERGIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N</td>\n",
       "      <td>AC</td>\n",
       "      <td>RIO BRANCO</td>\n",
       "      <td>AUTO POSTO AMAPA - EIRELI</td>\n",
       "      <td>00.529.581/0001-53</td>\n",
       "      <td>VIA CHICO MENDES</td>\n",
       "      <td>3570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AREAL</td>\n",
       "      <td>69906-119</td>\n",
       "      <td>GASOLINA ADITIVADA</td>\n",
       "      <td>03/01/2022</td>\n",
       "      <td>7,05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R$ / litro</td>\n",
       "      <td>VIBRA ENERGIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>AC</td>\n",
       "      <td>RIO BRANCO</td>\n",
       "      <td>AUTO POSTO ACAUAN LTDA</td>\n",
       "      <td>00.524.999/0001-78</td>\n",
       "      <td>RODOVIA AC 40</td>\n",
       "      <td>1800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VILA ACRE</td>\n",
       "      <td>69902-450</td>\n",
       "      <td>GASOLINA</td>\n",
       "      <td>03/01/2022</td>\n",
       "      <td>6,99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R$ / litro</td>\n",
       "      <td>VIBRA ENERGIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N</td>\n",
       "      <td>AC</td>\n",
       "      <td>RIO BRANCO</td>\n",
       "      <td>AUTO POSTO ACAUAN LTDA</td>\n",
       "      <td>00.524.999/0001-78</td>\n",
       "      <td>RODOVIA AC 40</td>\n",
       "      <td>1800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VILA ACRE</td>\n",
       "      <td>69902-450</td>\n",
       "      <td>ETANOL</td>\n",
       "      <td>03/01/2022</td>\n",
       "      <td>6,12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R$ / litro</td>\n",
       "      <td>VIBRA ENERGIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Regiao - Sigla Estado - Sigla   Municipio                    Revenda  \\\n",
       "0              N             AC  RIO BRANCO  AUTO POSTO AMAPA - EIRELI   \n",
       "1              N             AC  RIO BRANCO  AUTO POSTO AMAPA - EIRELI   \n",
       "2              N             AC  RIO BRANCO  AUTO POSTO AMAPA - EIRELI   \n",
       "3              N             AC  RIO BRANCO     AUTO POSTO ACAUAN LTDA   \n",
       "4              N             AC  RIO BRANCO     AUTO POSTO ACAUAN LTDA   \n",
       "\n",
       "       CNPJ da Revenda       Nome da Rua Numero Rua Complemento     Bairro  \\\n",
       "0   00.529.581/0001-53  VIA CHICO MENDES       3570         NaN      AREAL   \n",
       "1   00.529.581/0001-53  VIA CHICO MENDES       3570         NaN      AREAL   \n",
       "2   00.529.581/0001-53  VIA CHICO MENDES       3570         NaN      AREAL   \n",
       "3   00.524.999/0001-78     RODOVIA AC 40       1800         NaN  VILA ACRE   \n",
       "4   00.524.999/0001-78     RODOVIA AC 40       1800         NaN  VILA ACRE   \n",
       "\n",
       "         Cep             Produto Data da Coleta Valor de Venda  \\\n",
       "0  69906-119            GASOLINA     03/01/2022           6,99   \n",
       "1  69906-119              ETANOL     03/01/2022           5,99   \n",
       "2  69906-119  GASOLINA ADITIVADA     03/01/2022           7,05   \n",
       "3  69902-450            GASOLINA     03/01/2022           6,99   \n",
       "4  69902-450              ETANOL     03/01/2022           6,12   \n",
       "\n",
       "   Valor de Compra Unidade de Medida       Bandeira  \n",
       "0              NaN        R$ / litro  VIBRA ENERGIA  \n",
       "1              NaN        R$ / litro  VIBRA ENERGIA  \n",
       "2              NaN        R$ / litro  VIBRA ENERGIA  \n",
       "3              NaN        R$ / litro  VIBRA ENERGIA  \n",
       "4              NaN        R$ / litro  VIBRA ENERGIA  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfga.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renomear_colunas(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Renomeia colunas removendo espaços, hifens, parênteses e convertendo para minúsculo.\n",
    "    Ex.: \"Regiao - Sigla\" -> \"regiao_sigla\"\n",
    "    \"\"\"\n",
    "    # Se houver BOM (ex.: ï»¿Regiao - Sigla), você pode corrigir especificamente:\n",
    "    if 'ï»¿Regiao - Sigla' in df.columns:\n",
    "        df.rename(columns={'ï»¿Regiao - Sigla': 'Regiao - Sigla'}, inplace=True)\n",
    "    \n",
    "    df.columns = (\n",
    "        df.columns\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(' ', '_', regex=False)\n",
    "        .str.replace('-', '_', regex=False)\n",
    "        .str.replace('[()]', '', regex=True)\n",
    "        .str.replace('ã','a')    # se quiser remover acentos, pode incluir .str.normalize() ou algo mais sofisticado\n",
    "        .str.replace('ç','c')\n",
    "        # etc., se necessário\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def converter_tipos(df: pd.DataFrame, col_type_map: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Converte cada coluna para o tipo especificado no dicionário col_type_map,\n",
    "    onde a chave é o nome da coluna (já renomeada) e o valor é o tipo desejado:\n",
    "      - 'float'    -> converte para float, trocando vírgula por ponto se necessário\n",
    "      - 'int'      -> converte para inteiro\n",
    "      - 'datetime' -> converte para datetime (inferindo ou usando format)\n",
    "      - 'string'   -> converte para string\n",
    "    \"\"\"\n",
    "    for col, desired_type in col_type_map.items():\n",
    "        if col not in df.columns:\n",
    "            continue  # se a coluna não existir no DF, pula\n",
    "        \n",
    "        if desired_type == 'float':\n",
    "            # Exemplo: se houver vírgula decimal, trocar por ponto\n",
    "            df[col] = pd.to_numeric(\n",
    "                df[col].astype(str).str.replace(',', '.'),\n",
    "                errors='coerce'\n",
    "            )\n",
    "        elif desired_type == 'int':\n",
    "            df[col] = pd.to_numeric(df[col], downcast='integer', errors='coerce')\n",
    "        elif desired_type == 'datetime':\n",
    "            # Se a data for D/M/Y, use dayfirst=True ou format='%d/%m/%Y'\n",
    "            # Se for Y-M-D, use dayfirst=False ou format='%Y-%m-%d'\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True)\n",
    "        else:\n",
    "            # Qualquer outro caso (ou 'string')\n",
    "            df[col] = df[col].astype('string')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_arquivo(input_path, output_path, col_type_map, sep=';'):\n",
    "    \"\"\"\n",
    "    Lê o arquivo CSV em 'input_path', renomeia colunas, converte tipos\n",
    "    e salva em 'output_path'.\n",
    "    \"\"\"\n",
    "    # Lê o CSV\n",
    "    df = pd.read_csv(input_path, sep=sep, low_memory=False)\n",
    "    \n",
    "    # Renomeia colunas\n",
    "    df = renomear_colunas(df)\n",
    "    \n",
    "    # Converte tipos\n",
    "    df = converter_tipos(df, col_type_map)\n",
    "    \n",
    "    # Salva o DataFrame tratado em formato Pickle\n",
    "    df.to_pickle(output_path)\n",
    "    print(f\"Arquivo '{input_path}' processado e salvo como pickle em '{output_path}'.\")\n",
    "    \n",
    "    return df  # se quiser retornar o DF em memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo 'dataset\\vendas-combustiveis-segmento-m3-2012-2025.csv' processado e salvo como pickle em 'dataset\\vendas-combustiveis-segmento-m3-2012-2025_tratado.pkl'.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Ajuste os caminhos conforme necessário\n",
    "    input_file = r\"dataset\\vendas-combustiveis-segmento-m3-2012-2025.csv\"\n",
    "    output_file = r\"dataset\\vendas-combustiveis-segmento-m3-2012-2025_tratado.pkl\"\n",
    "    \n",
    "    # Dicionário de tipos para o arquivo \"precos-gasolina-etanol-01\"\n",
    "    col_type_map_precos = {\n",
    "        'regiao_sigla': 'string',\n",
    "        'estado_sigla': 'string',\n",
    "        'municipio': 'string',\n",
    "        'revenda': 'string',\n",
    "        'cnpj_da_revenda': 'string',\n",
    "        'nome_da_rua': 'string',\n",
    "        'numero_rua': 'string',\n",
    "        'complemento': 'string',\n",
    "        'bairro': 'string',\n",
    "        'cep': 'string',\n",
    "        'produto': 'string',\n",
    "        'data_da_coleta': 'datetime',\n",
    "        'valor_de_venda': 'float',\n",
    "        'valor_de_compra': 'float',\n",
    "        'unidade_de_medida': 'string',\n",
    "        'bandeira': 'string'\n",
    "    }\n",
    "\n",
    "    col_type_map_producao = {\n",
    "    'ano': 'int',\n",
    "    'mes': 'int',\n",
    "    'grande_regiao': 'string',\n",
    "    'unidade_da_federacao': 'string',\n",
    "    'produto': 'string',\n",
    "    'localizacao': 'string',\n",
    "    'producao': 'float'\n",
    "    }\n",
    "\n",
    "    col_type_map_gasolina_mun = {\n",
    "    'ano': 'int',\n",
    "    'grande_regiao': 'string',\n",
    "    'uf': 'string',\n",
    "    'produto': 'string',\n",
    "    'codigo_ibge': 'int',\n",
    "    'municipio': 'string',\n",
    "    'vendas': 'float'\n",
    "    }\n",
    "    col_type_map_diesel_mun = {\n",
    "    'ano': 'int',\n",
    "    'grande_regiao': 'string',\n",
    "    'uf': 'string',\n",
    "    'produto': 'string',\n",
    "    'codigo_ibge': 'int',\n",
    "    'municipio': 'string',\n",
    "    'vendas': 'float'\n",
    "    }\n",
    "    col_type_map_vendas_comb = {\n",
    "    'ano': 'int',\n",
    "    'mes': 'int',\n",
    "    'grande_regiao': 'string',\n",
    "    'unidade_da_federacao': 'string',\n",
    "    'produto': 'string',\n",
    "    'vendas': 'float'\n",
    "    }\n",
    "\n",
    "\n",
    "    \n",
    "    # Se o encoding original for diferente de utf-8-sig, ajuste (exemplo: 'latin-1')\n",
    "    processar_arquivo(input_file, output_file, col_type_map_vendas_comb, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38151 entries, 0 to 38150\n",
      "Data columns (total 6 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   ano                   38151 non-null  int16  \n",
      " 1   mês                   38151 non-null  object \n",
      " 2   unidade_da_federacao  38151 non-null  string \n",
      " 3   produto               38151 non-null  string \n",
      " 4   segmento              38151 non-null  object \n",
      " 5   vendas                38151 non-null  float64\n",
      "dtypes: float64(1), int16(1), object(2), string(2)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "teste2 = pd.read_pickle(\"dataset/vendas-combustiveis-segmento-m3-2012-2025_tratado.pkl\")\n",
    "teste2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converter_coluna_mes(file_path):\n",
    "    # Carrega o DataFrame do arquivo PKL\n",
    "    df = pd.read_pickle(file_path)\n",
    "    \n",
    "    # Verifica se existe a coluna \"mes\" ou \"mês\"\n",
    "    col_mes = None\n",
    "    for col in ['mes', 'mês']:\n",
    "        if col in df.columns:\n",
    "            col_mes = col\n",
    "            break\n",
    "    \n",
    "    if col_mes is not None:\n",
    "        # Converte a coluna para numérico\n",
    "        df[col_mes] = pd.to_numeric(df[col_mes], errors='coerce')\n",
    "        print(f\"Coluna '{col_mes}' convertida para numérico em {file_path}.\")\n",
    "        # Salva novamente em formato PKL\n",
    "        df.to_pickle(file_path)\n",
    "        print(f\"Arquivo {file_path} salvo com a coluna '{col_mes}' convertida.\")\n",
    "    else:\n",
    "        print(f\"Arquivo {file_path} não possui a coluna 'mes' ou 'mês'.\")\n",
    "\n",
    "def processar_todos_pickle(folder_path):\n",
    "    # Procura todos os arquivos .pkl na pasta especificada\n",
    "    arquivos = glob.glob(os.path.join(folder_path, '*.pkl'))\n",
    "    for file in arquivos:\n",
    "        converter_coluna_mes(file)\n",
    "\n",
    "# Exemplo de uso:\n",
    "if __name__ == '__main__':\n",
    "    pasta = r'dataset\\arquivos'\n",
    "    processar_todos_pickle(pasta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
